{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import glob, re, sys, random, time\n",
    "from collections import deque\n",
    "\n",
    "np.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_ACTIONS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.optimizers import Adam, RMSprop\n",
    "\n",
    "class DQN:\n",
    "    def __init__(self):\n",
    "        self.test = False\n",
    "        self.memory  = deque(maxlen=50000)\n",
    "        \n",
    "        self.gamma = 0.85\n",
    "        self.epsilon = 1.0\n",
    "        self.epsilon_min = 0.1\n",
    "        self.epsilon_decay = 0.99995\n",
    "        self.learning_rate = 0.005\n",
    "        self.tau = .125\n",
    "\n",
    "        self.model        = self.create_model()\n",
    "        self.target_model = self.create_model()\n",
    "\n",
    "    def create_model(self):\n",
    "        model = models.Sequential()\n",
    "        model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 2)))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(layers.MaxPooling2D((2, 2)))\n",
    "        model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "        model.add(layers.Dropout(0.4))\n",
    "        model.add(layers.Flatten())\n",
    "        model.add(layers.Dense(64, activation='relu'))\n",
    "        model.add(layers.Dense(NUM_ACTIONS))\n",
    "        model.compile(loss=\"mean_squared_error\", \n",
    "            optimizer=Adam(lr=self.learning_rate))\n",
    "        return model\n",
    "\n",
    "    def act(self, state):\n",
    "        self.epsilon *= self.epsilon_decay\n",
    "        self.epsilon = max(self.epsilon_min, self.epsilon)\n",
    "        if np.random.random() < self.epsilon and not self.test:\n",
    "            return np.random.randint(0, NUM_ACTIONS)\n",
    "        return np.argmax(self.model.predict(state)[0])\n",
    "\n",
    "    def remember(self, state, action, reward, new_state, done):\n",
    "        self.memory.append([state, action, reward, new_state, done])\n",
    "\n",
    "    def replay(self):\n",
    "        \"\"\"\n",
    "        batch_size = 32\n",
    "        if len(self.memory) < batch_size: \n",
    "            return\n",
    "\n",
    "        samples = random.sample(self.memory, batch_size)\n",
    "        for sample in samples:\n",
    "            state, action, reward, new_state, done = sample\n",
    "            target = self.target_model.predict(state)\n",
    "            if done:\n",
    "                target[0][action] = reward\n",
    "            else:\n",
    "                Q_future = max(self.target_model.predict(new_state)[0])\n",
    "                target[0][action] = reward + Q_future * self.gamma\n",
    "            self.model.fit(state, target, epochs=1, verbose=0)\n",
    "        \"\"\"\n",
    "        batch_size = 32\n",
    "        if len(self.memory) < batch_size: \n",
    "            return\n",
    "\n",
    "        #samples = random.sample(self.memory, batch_size)\n",
    "        #for sample in samples:\n",
    "        #    state, action, reward, new_state, done = sample\n",
    "        #    target = self.target_model.predict(state)\n",
    "        #    if done:\n",
    "        #        target[0][action] = reward\n",
    "        #    else:\n",
    "        #        Q_future = max(self.target_model.predict(new_state)[0])\n",
    "        #        target[0][action] = reward + Q_future * self.gamma\n",
    "        #    self.model.fit(state, target, epochs=1, verbose=False)\n",
    "        \n",
    "        samples = np.array(random.sample(self.memory, batch_size))\n",
    "        #print(\"Samples\", samples)\n",
    "        state = np.stack(samples[:,0])\n",
    "        action = samples[:,1].astype(int)\n",
    "        #print(\"state\", state)\n",
    "        #print(\"Action\", action)\n",
    "        reward = samples[:,2]\n",
    "        #print(\"Reward\", reward)\n",
    "        new_state = np.stack(samples[:,3])\n",
    "        #print(\"State\", state.shape)\n",
    "        target = self.target_model.predict(state)\n",
    "        #print(\"Target\", target)\n",
    "        terminal = np.array(samples[:,4])\n",
    "        \n",
    "        #print(\"Predict\", self.target_model.predict(new_state))\n",
    "        Q_future = np.max(self.target_model.predict(new_state), axis=1)\n",
    "        #print(\"QFUTURE\", Q_future)\n",
    "\n",
    "        terminal_indexes = np.nonzero(terminal)\n",
    "        result = reward + Q_future * self.gamma\n",
    "        result[terminal_indexes] = reward[terminal_indexes]\n",
    "\n",
    "        target[np.arange(len(target)), action] = result\n",
    "        #print(\"Target\",target)\n",
    "        self.model.fit(state, target, epochs=1, verbose=False)\n",
    "\n",
    "\n",
    "    def target_train(self):\n",
    "        weights = self.model.get_weights()\n",
    "        target_weights = self.target_model.get_weights()\n",
    "        for i in range(len(target_weights)):\n",
    "            target_weights[i] = weights[i] * self.tau + target_weights[i] * (1 - self.tau)\n",
    "        self.target_model.set_weights(target_weights)\n",
    "\n",
    "    def save_model(self, fn):\n",
    "        self.model.save(fn)\n",
    "\n",
    "    def load_model(self, fn):\n",
    "        self.model.load_weights(fn)\n",
    "        self.target_model.load_weights(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_CLASSES = 8\n",
    "\n",
    "def create_critic_model():\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.MaxPooling2D((2, 2)))\n",
    "    model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "    model.add(layers.Dropout(0.4))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(64, activation='relu'))\n",
    "    model.add(layers.Dense(NUM_CLASSES, activation=\"softmax\"))\n",
    "    model.compile(optimizer='adam',\n",
    "                  loss=\"categorical_crossentropy\",\n",
    "                  metrics=['accuracy'])\n",
    "    return model\n",
    "\n",
    "critic = create_critic_model()\n",
    "critic.load_weights(\"models/classifier.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "completed trial 0 avg_r -0.8854856047034264 epsilon 0.9900495862284902\n",
      "completed trial 1 avg_r -0.8215262812376022 epsilon 0.9801981831912049\n",
      "completed trial 2 avg_r -0.9728642098791898 epsilon 0.9704448056903707\n",
      "completed trial 3 avg_r -0.7813910723477602 epsilon 0.9607884783313398\n",
      "completed trial 4 avg_r -0.9765633733570576 epsilon 0.9512282354250445\n",
      "completed trial 5 avg_r -0.9342564098816365 epsilon 0.9417631208914232\n",
      "completed trial 6 avg_r -0.8128487020730972 epsilon 0.9323921881638054\n",
      "completed trial 7 avg_r -0.8439525393862277 epsilon 0.9231145000942527\n",
      "completed trial 8 avg_r -0.8526483277976513 epsilon 0.9139291288598353\n",
      "completed trial 9 avg_r -0.9600800232985057 epsilon 0.9048351558698455\n",
      "completed trial 10 avg_r -0.8760180009901524 epsilon 0.8958316716739327\n",
      "completed trial 11 avg_r -0.9190293354168534 epsilon 0.8869177758711543\n",
      "completed trial 12 avg_r -0.85685232270509 epsilon 0.8780925770199298\n",
      "completed trial 13 avg_r -0.8573388416692614 epsilon 0.8693551925488907\n",
      "completed trial 14 avg_r -0.8581848807260394 epsilon 0.8607047486686187\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-52181a6a9162>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m \u001b[0;31m# TODO\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mprobs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcritic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcanvas\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprobs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     86\u001b[0m       raise ValueError('{} is not supported in multi-worker mode.'.format(\n\u001b[1;32m     87\u001b[0m           method.__name__))\n\u001b[0;32m---> 88\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m   return tf_decorator.make_decorator(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, x, batch_size, verbose, steps, callbacks, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1247\u001b[0m           \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1248\u001b[0m           \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1249\u001b[0;31m           model=self)\n\u001b[0m\u001b[1;32m   1250\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1251\u001b[0m       \u001b[0;31m# Container that configures and calls `tf.keras.Callback`s.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weight, batch_size, steps_per_epoch, initial_epoch, epochs, shuffle, class_weight, max_queue_size, workers, use_multiprocessing, model)\u001b[0m\n\u001b[1;32m   1110\u001b[0m         \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1111\u001b[0m         \u001b[0mdistribution_strategy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1112\u001b[0;31m         model=model)\n\u001b[0m\u001b[1;32m   1113\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1114\u001b[0m     \u001b[0mstrategy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mds_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_strategy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, sample_weights, sample_weight_modes, batch_size, epochs, steps, shuffle, **kwargs)\u001b[0m\n\u001b[1;32m    262\u001b[0m                \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    263\u001b[0m                **kwargs):\n\u001b[0;32m--> 264\u001b[0;31m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTensorLikeDataAdapter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    265\u001b[0m     \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_tensorlike\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    266\u001b[0m     sample_weight_modes = broadcast_sample_weight_modes(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, x, y, **kwargs)\u001b[0m\n\u001b[1;32m    137\u001b[0m         \u001b[0muse\u001b[0m \u001b[0mit\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0many\u001b[0m \u001b[0mrequired\u001b[0m \u001b[0margument\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mprovide\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    138\u001b[0m     \"\"\"\n\u001b[0;32m--> 139\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcan_handle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    140\u001b[0m       raise ValueError(\"{} Cannot handle input {}, {}\".format(\n\u001b[1;32m    141\u001b[0m           self.__class__, x, y))\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/data_adapter.py\u001b[0m in \u001b[0;36mcan_handle\u001b[0;34m(x, y)\u001b[0m\n\u001b[1;32m    237\u001b[0m     \u001b[0;31m# TODO(kaftan): Check performance implications of using a flatten\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m     \u001b[0;31m#  here for other types of inputs.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 239\u001b[0;31m     \u001b[0mflat_inputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    240\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    241\u001b[0m       \u001b[0mflat_inputs\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mnest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/util/nest.py\u001b[0m in \u001b[0;36mflatten\u001b[0;34m(structure, expand_composites)\u001b[0m\n\u001b[1;32m    320\u001b[0m     \u001b[0mTypeError\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mThe\u001b[0m \u001b[0mnest\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mcontains\u001b[0m \u001b[0ma\u001b[0m \u001b[0mdict\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mnon\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0msortable\u001b[0m \u001b[0mkeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    321\u001b[0m   \"\"\"\n\u001b[0;32m--> 322\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0m_pywrap_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFlatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstructure\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpand_composites\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    323\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    324\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 432x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def save_canvas(canvas, trial):\n",
    "    plt.imshow(canvas, cmap=\"gray\")\n",
    "    plt.savefig(f\"output2/out-big{trial}.png\")\n",
    "    plt.clf()\n",
    "    \n",
    "gamma   = 0.9\n",
    "epsilon = .95\n",
    "\n",
    "trials  = 100000\n",
    "trial_len = 200\n",
    "\n",
    "dqn_agent = DQN()\n",
    "dqn_agent.load_model(\"models/bootstrapbig.h5\")\n",
    "dqn_agent.test = True\n",
    "steps = []\n",
    "for trial in range(trials):\n",
    "    canvas = np.zeros((28, 28))\n",
    "    pos = np.random.randint(0,28,size=(2))\n",
    "    brush_map = np.zeros((28, 28))\n",
    "    brush_map[pos[0], pos[1]] = 1\n",
    "    \n",
    "    reward_sum = 0\n",
    "    reward_num = 0\n",
    "    \n",
    "    #print(\"initial position\", pos)\n",
    "    for step in range(trial_len):\n",
    "        old_canvas = canvas.copy()\n",
    "        old_map = brush_map.copy()\n",
    "        old_state = np.dstack([old_canvas, old_map])\n",
    "        \n",
    "        action = dqn_agent.act(old_state.reshape(1,28,28,2))\n",
    "        #print(old_state.shape)\n",
    "        \n",
    "        if action == 0:\n",
    "            if pos[1] < 27:\n",
    "                pos = pos + [0, 1]\n",
    "        elif action == 1:\n",
    "            if pos[1] > 0:\n",
    "                pos = pos - [0, 1]\n",
    "        elif action == 2:\n",
    "            if pos[0] < 27:\n",
    "                pos = pos + [1, 0]\n",
    "        elif action == 3:\n",
    "            if pos[0] > 0:\n",
    "                pos = pos - [1, 0]\n",
    "        elif action == 4:\n",
    "            canvas[pos[0], pos[1]] = 1\n",
    "            \n",
    "        new_map = np.zeros((28,28))\n",
    "        new_map[pos[0], pos[1]] = 1\n",
    "        new_state = np.dstack([canvas, new_map])\n",
    "        \n",
    "        done = False # TODO\n",
    "        \n",
    "        probs = critic.predict(canvas.reshape(1,28,28,1))[0]\n",
    "        \n",
    "        reward = 2*probs[6] - np.sum(probs)\n",
    "\n",
    "        reward_sum += reward\n",
    "        reward_num += 1\n",
    "        \n",
    "        #print(new_state.shape)\n",
    "        dqn_agent.remember(old_state, action, reward, new_state, done)\n",
    "\n",
    "        #dqn_agent.replay()       # internally iterates default (prediction) model\n",
    "        \n",
    "        #if step % 20 == 0:\n",
    "            #dqn_agent.target_train() # iterates target model\n",
    "\n",
    "        brush_map = new_map\n",
    "        \n",
    "        if done:\n",
    "            break\n",
    "    \n",
    "    print(\"completed trial\", trial, \"avg_r\", reward_sum/reward_num, \"epsilon\", dqn_agent.epsilon)\n",
    "    \n",
    "    save_canvas(canvas, trial)\n",
    "    \n",
    "    #if trial % 50 == 0:\n",
    "    #    print(\"saving model\")\n",
    "    #    dqn_agent.save_model(f\"models/painter-no-bug{trial}.h5\")\n",
    "    \"\"\"\n",
    "    if step >= 199:\n",
    "        print(\"Failed to complete in trial {}\".format(trial))\n",
    "        if step % 10 == 0:\n",
    "            dqn_agent.save_model(\"trial-{}.model\".format(trial))\n",
    "    else:\n",
    "        print(\"Completed in {} trials\".format(trial))\n",
    "        dqn_agent.save_model(\"success.model\")\n",
    "        break\n",
    "    \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.stack([np.array([[1,2],[3,4]]), np.array([[5,6],[7,8]])]).reshape(2,2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
